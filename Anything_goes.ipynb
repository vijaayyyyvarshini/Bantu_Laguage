{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4RrsvT54lBcq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJpXnwn0gs5h",
        "outputId": "705ab598-4ec2-42fc-de75-53136904bd02"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/MyDrive/SLU Semesters/SLU 3rd Semester/NLP/Fourth Competition\n",
        "%ls "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "uXCmt0qR2N3W"
      },
      "outputs": [],
      "source": [
        "GRAMS_NUM = 6\n",
        "TRAIN_PATH = \"cwe-train.txt\"\n",
        "TEST_PATH = \"cwe-test.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QOhxm93EoNm-"
      },
      "outputs": [],
      "source": [
        "training_file = open(TRAIN_PATH, \"r\")\n",
        "all_words = training_file.read().split(\" \")\n",
        "splitted = []\n",
        "\n",
        "for line in all_words:\n",
        "  splitted.append(line.lower().strip())\n",
        "\n",
        "train = ' '.join(splitted[:int(len(splitted) * 0.8)])\n",
        "test = ' '.join(splitted[int(len(splitted) * 0.8):])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcf_Eej4NyHZ",
        "outputId": "9f3bdcd2-af61-4a46-bdf4-98368b06625f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "482816"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "DBsTcmzwh5ne"
      },
      "outputs": [],
      "source": [
        "test_file = open(TEST_PATH, \"r\")\n",
        "\n",
        "all_test_words = test_file.read().split(\" \")\n",
        "splitted_test = []\n",
        "\n",
        "for line in all_test_words:\n",
        "  splitted_test.append(line.lower().strip())\n",
        "\n",
        "final_test = ' '.join(splitted_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "hiyNiljihBev"
      },
      "outputs": [],
      "source": [
        "# Source: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7\n",
        "# create a character mapping index\n",
        "def encode_seq(seq, data_new):\n",
        "    chars = sorted(list(set(data_new)))\n",
        "    mapping = dict((c, i) for i, c in enumerate(chars))\n",
        "    sequences = list()\n",
        "    for line in seq:\n",
        "        # integer encode line\n",
        "        encoded_seq = [mapping[char] for char in line]\n",
        "        # store\n",
        "        sequences.append(encoded_seq)\n",
        "    return sequences, mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VeI_0pn6i9N3"
      },
      "outputs": [],
      "source": [
        "# Source: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7\n",
        "# define model\n",
        "def build_model(vocab):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab, 20, input_length= GRAMS_NUM -1, trainable=True))\n",
        "    model.add(GRU(25, recurrent_dropout=0.1, dropout=0.1))\n",
        "    model.add(Dense(vocab, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "f_whfujvPAXi"
      },
      "outputs": [],
      "source": [
        "# Source: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7\n",
        "data = train\n",
        "\n",
        "n_grams = [''.join(data[i:i + GRAMS_NUM]) for i in (range(len(data) - GRAMS_NUM + 1))]\n",
        "n_grams, mapping = encode_seq(n_grams, data)\n",
        "\n",
        "vocab = len(mapping)\n",
        "sequences = np.array(n_grams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SDwsNaQqWu4",
        "outputId": "2f361446-daeb-4e49-f4a4-f087be9d2cd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (434529, 5) Val shape: (48282, 5)\n"
          ]
        }
      ],
      "source": [
        "# Source: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "from keras.layers import LSTM, Dense, GRU, Embedding\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "# create X and y\n",
        "x, y = sequences[:, :-1], sequences[:, -1]\n",
        "# one hot encode y\n",
        "y = to_categorical(y, num_classes=vocab)\n",
        "# create train and validation sets\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "\n",
        "print('Train shape:', x_tr.shape, 'Val shape:', x_val.shape)\n",
        "\n",
        "model = build_model(vocab)\n",
        "# https://keras.io/api/callbacks/early_stopping/\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=5)\n",
        "\n",
        "# model.fit(x_tr, y_tr, epochs= 20, verbose=1, validation_data=(x_val, y_val), callbacks= callback, batch_size= 50)\n",
        "# model.save('./20epoch_50batch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-7WzrPZnsuw6"
      },
      "outputs": [],
      "source": [
        "# Source: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7\n",
        "GRAMS_NUM = 6\n",
        "n_grams = [''.join(final_test[i:i+ GRAMS_NUM]) for i in (range(len(final_test) - GRAMS_NUM + 1))]\n",
        "n_grams, mapping = encode_seq(n_grams, final_test)\n",
        "\n",
        "vocab = len(mapping)\n",
        "sequences = np.array(n_grams)\n",
        "\n",
        "x_test, y_test = sequences[:, :-1], sequences[:, -1]\n",
        "# one hot encode y\n",
        "y_test = to_categorical(y_test, num_classes=vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLCENHapnvWn",
        "outputId": "c1fcf501-ea67-4281-d121-157c442e3ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1929/1929 [==============================] - 4s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "from math import log2\n",
        "\n",
        "model = keras.models.load_model('./20epoch_50batch')\n",
        "predict = model.predict(x_test)\n",
        "\n",
        "entropy = 0\n",
        "\n",
        "for pr in range(len(sequences)):\n",
        "  entropy = entropy -  (1/(len(predict))) * log2(predict[pr][sequences[:, -1][pr]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVlN3BePn9Wz",
        "outputId": "65bb9ea7-5963-417b-dd9e-ee21f3c640f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.19166339627591"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entropy"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
