{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4RrsvT54lBcq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJpXnwn0gs5h",
        "outputId": "9d1e2176-01da-4883-a14a-40e31a94e732"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/SLU Semesters/SLU 3rd Semester/NLP/Fourth Competition\n",
            "\u001b[0m\u001b[01;34m20epoch_50batch\u001b[0m/     cwe-test.txt   sw-test.txt\n",
            "Anything_goes.ipynb  cwe-train.txt  sw-train.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/MyDrive/SLU Semesters/SLU 3rd Semester/NLP/Fourth Competition\n",
        "%ls "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uXCmt0qR2N3W"
      },
      "outputs": [],
      "source": [
        "GRAMS_NUM = 6\n",
        "TRAIN_PATH = \"cwe-train.txt\"\n",
        "TEST_PATH = \"cwe-test.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QOhxm93EoNm-"
      },
      "outputs": [],
      "source": [
        "training_file = open(TRAIN_PATH, \"r\")\n",
        "all_words = training_file.read().split(\" \")\n",
        "splitted = []\n",
        "\n",
        "for line in all_words:\n",
        "  splitted.append(line.lower().strip())\n",
        "\n",
        "train = ' '.join(splitted[:int(len(splitted) * 0.8)])\n",
        "test = ' '.join(splitted[int(len(splitted) * 0.8):])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcf_Eej4NyHZ",
        "outputId": "e1e693a1-9e79-4dc7-cf80-263f38c19a45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "482816"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DBsTcmzwh5ne"
      },
      "outputs": [],
      "source": [
        "test_file = open(TEST_PATH, \"r\")\n",
        "\n",
        "all_test_words = test_file.read().split(\" \")\n",
        "splitted_test = []\n",
        "\n",
        "for line in all_test_words:\n",
        "  splitted_test.append(line.lower().strip())\n",
        "\n",
        "final_test = ' '.join(splitted_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hiyNiljihBev"
      },
      "outputs": [],
      "source": [
        "# Source: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7\n",
        "# create a character mapping index\n",
        "def encode_seq(seq, data_new):\n",
        "    chars = sorted(list(set(data_new)))\n",
        "    mapping = dict((c, i) for i, c in enumerate(chars))\n",
        "    sequences = list()\n",
        "    for line in seq:\n",
        "        # integer encode line\n",
        "        encoded_seq = [mapping[char] for char in line]\n",
        "        # store\n",
        "        sequences.append(encoded_seq)\n",
        "    return sequences, mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VeI_0pn6i9N3"
      },
      "outputs": [],
      "source": [
        "# Source: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7\n",
        "# define model\n",
        "def build_model(vocab):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab, 20, input_length= GRAMS_NUM -1, trainable=True))\n",
        "    model.add(GRU(25, recurrent_dropout=0.1, dropout=0.1))\n",
        "    model.add(Dense(vocab, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "f_whfujvPAXi"
      },
      "outputs": [],
      "source": [
        "# Source: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7\n",
        "data = train\n",
        "\n",
        "n_grams = [''.join(data[i:i + GRAMS_NUM]) for i in (range(len(data) - GRAMS_NUM + 1))]\n",
        "n_grams, mapping = encode_seq(n_grams, data)\n",
        "\n",
        "vocab = len(mapping)\n",
        "sequences = np.array(n_grams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SDwsNaQqWu4",
        "outputId": "df52668f-d58e-4142-9ab1-c2427e8f4595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (434529, 5) Val shape: (48282, 5)\n"
          ]
        }
      ],
      "source": [
        "# Source: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "import keras\n",
        "from keras.layers import LSTM, Dense, GRU, Embedding\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "# create X and y\n",
        "x, y = sequences[:, :-1], sequences[:, -1]\n",
        "# one hot encode y\n",
        "y = to_categorical(y, num_classes=vocab)\n",
        "# create train and validation sets\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(x, y, test_size=0.1, random_state=42)\n",
        "\n",
        "print('Train shape:', x_tr.shape, 'Val shape:', x_val.shape)\n",
        "\n",
        "model = build_model(vocab)\n",
        "# https://keras.io/api/callbacks/early_stopping/\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=5)\n",
        "\n",
        "model.fit(x_tr, y_tr, epochs= 20, verbose=1, validation_data=(x_val, y_val), callbacks= callback, batch_size= 50)\n",
        "model.save('./20epoch_50batch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-7WzrPZnsuw6"
      },
      "outputs": [],
      "source": [
        "# Source: https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-language-model-nlp-python-code/#h2_7\n",
        "GRAMS_NUM = 6\n",
        "n_grams = [''.join(final_test[i:i+ GRAMS_NUM]) for i in (range(len(final_test) - GRAMS_NUM + 1))]\n",
        "n_grams, mapping = encode_seq(n_grams, final_test)\n",
        "\n",
        "vocab = len(mapping)\n",
        "sequences = np.array(n_grams)\n",
        "\n",
        "x_test, y_test = sequences[:, :-1], sequences[:, -1]\n",
        "# one hot encode y\n",
        "y_test = to_categorical(y_test, num_classes=vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLCENHapnvWn",
        "outputId": "555033a3-5637-41d1-9e58-6cde95a6703e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1929/1929 [==============================] - 5s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "from math import log2\n",
        "\n",
        "model = keras.models.load_model('./20epoch_50batch')\n",
        "predict = model.predict(x_test)\n",
        "\n",
        "entropy = 0\n",
        "\n",
        "for pr in predict:\n",
        "  entropy = entropy -  (1/(len(predict))) * log2(max(pr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVlN3BePn9Wz",
        "outputId": "1d188f38-b89f-4b2c-9b28-4f4ac7ac20ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.1953847665600932"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "entropy"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
