# Bantu-Language-Modeling-
This challenge involves language modeling for two closely-related languages in the Bantu language familyLinks to an external site.: SwahiliLinks to an external site., spoken by more than 100 million people in eastern and southern Africa, and KwereLinks to an external site., spoken by about 100,000 people in central Tanzania.

Introduction: This challenge involves language modeling for two closely-related languages in the Bantu language familyLinks to an external site.: SwahiliLinks to an external site., spoken by more than 100 million people in eastern and southern Africa, and KwereLinks to an external site., spoken by about 100,000 people in central Tanzania.  Bantu languages have complex morphology, especially the verbs; a single verbal stem can have thousands or even millions of different possible forms. For this reason, language technologies which require a fixed vocabulary of words are simply not feasible. One of the aims of this challenge is therefore to explore the possibility of building character-level language models for the Bantu languages. The other interesting research direction here stems from the fact that Swahili is relatively well-resourced in terms of NLP technology and corpora, while Kwere is not. There is a New Testament translation of Kwere available online, but very little else in terms of corpus material or social media presence in the language. But since the two languages are so similar linguistically and orthographically, this opens the possibility of “transferring” knowledge from Swahili to Kwere when learning a language model. I honestly don't know if this will work, but even a negative result would be interesting!

Training/Test Set: For each language I have provided a plain text training corpus assembled from texts found on the web. The Kwere corpus is a subset of the New Testament translation, and contains about 85,000 words (600k characters). The Swahili corpus consists of a range of material from blogs, Twitter, new sites, etc.; about 6 million words (over 39 million characters). The training texts were segmented by sentences, shuffled, and lowercased. For simplicity, I fixed a “vocabulary” of 48 ASCII characters for both languages: [ !"'(),-.0-9:;?a-z], and discarded any sentences containing characters outside this range. The test corpora were produced similarly. The Kwere test corpus contains about 8700 words (61k characters) and the Swahili test corpus contains about 528k words (3.45 million characters). As always, if you need development data in order to tune the parameters of your language models, you'll need to take subsets of the training data for that. 

*** Download Training Data (16MB)Download Download Training Data (16MB)

Evaluation: Your goal is to produce language models with the smallest cross-entropy (in units of bits per character) :

where 

are the characters of the test corpus. Note that this is the log base 2! TensorFlow and other neural network libraries often report log loss as natural logs, so be sure you double-check your computations.

Deliverables and Grading: As in the first two challenges of the semester, you must submit, for each language, one model implemented “from scratch” and one “anything goes” implementation. So that is four separate language models which should all be delivered. For the “anything goes” models, you can use any external libraries you want, but I'll ask you not to use additional data for training your models, since anything you find for Kwere is almost certain to overlap with the test corpus (and while this would be less likely for Swahili, it is still a real possibility). You are permitted to use the Swahili training data in training either of your Kwere language models (and vice versa). Details regarding the format of your submission and the grading scheme are provided in the Rubric for NLP Challenges document.

For this particular challenge, the program you submit should read the training data files sw-train.txt and cwe-train.txt from the same directory it's launched from. There is a sample notebookLinks to an external site. in the course github repo that you can use to begin your work (of course you won't be able to do the final evaluation with the sw-test.txt and cwe-test.txt files, but you can (and should!) track your progress by setting aside a development set). I have functions in the notebook that return the probability of a character given the history of characters preceding it (with trivial implementations). However you implement your language models, it is essential that the probabilities for all 48 characters with a given history sum to 1.0! In other words, you must produce a conditional probability distribution at each step — returning probabilities that sum to more than 1.0 is an easy way to “cheat” and I'll be checking carefully that this isn't the case. You are free to restructure this code however you'd like, but I'd like the last thing in your program to be a call to the “evaluate” function which displays the cross entropies of your four language models on the test sets.

How to submit: The best way to submit your code is by committing it to a git repository (on github or on the CS Department gitlab instanceLinks to an external site. for example) that I'd be able to clone.
